代价函数的概念
弄清楚如何把最有可能的直线与我们的数据相拟合

线性回归
h thea(x) = thea0 + thea1*x

thea 我们称为模型参数

要做的是如何选择这两个参数值thea0 thea1

thea0和thea1不同会得到不同的假设函数

目标： 得出thea0 thea1这两个参数的值
来让假设函数表示的直线尽量的与这些数据拟合

定义： 在线性回归中我们要解决的是一个最小化问题

找到能使式子最小的 thea0 thea1

我们定义一个代价函数

J(thea0,thea1）= (1/2m)sum m-i(h(x)-y)^2

对J(thea0,thea1)求最小值

然后取能够使式子最小值的thea1,thea0

代价函数也被称为平方误差代价函数 解决回归问题是一个合理的选择
对于大多数线性回归非常合理

 ================================================================
 代价函数(1)

理解代价函数是用来做什么的

我们希望找到一条与数据拟合的直线 
所以构造了假设函数h

代价函数J(thea1,thea0)
优化目标 minimize(J(thea1,thea0))

为了使代价函数更好的可视化  我们采用只有一个参数的假设函数
h(x) = thea1*x  thea0=0

代价函数J(thea1)
优化目标 minimize(J(thea1))

假设函数h(x)  是一个关于x的函数
代价函数J(thea1) 是一个关于thea1的函数 控制直线的斜率

只要代价函数最小则最拟合
而且代价函数是一个凹进去的二次函数  最低点则为最优
===================================================================
代价函数(2)

假设函数
参数
代价函数
优化目标

这次是保留所有参数 thea0 thea1

3d曲面图形

曲面的高度 就是我们想得到的值 
而且所以可以看出子阿曲面最低点 就是我们想要的值

使用等高线 来展示

等高线每个点值都是一样的


===================================================================



