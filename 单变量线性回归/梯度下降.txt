一种可以自动找到使函数J最小的thea0,thea1的算法

线性回归 和其他领域

梯度下降算法 应用于任意函数

函数J(thea1,thea0)
最小化

算法思路
我们要做的是开始给定thea0,thea1初始值
我们要做的是不停地一点点地改变thea1,thea0来使得代价函数变小
直到我们找到J的最小值 或者局部最小值

一步一步慢慢下降到最低点   每一步都判断最优的下降

theaj = theaj - arfa(d/d(theaj))J(thea1,thea0) (for j = 0 and j=1)

:= 是一个赋值符号 

= 则是判定


arfa 学习率 arfa用来控制梯度下降时  我们迈出多大的步子

arfa越大 梯度下降迅速
arfa越小 梯度下降缓慢

arfa后面有个导数项

细节：
我们要更新thea1 thea1 这是个更新方程
我们需要同时更新
thea1 = thea1- 某项
thea0 = thea0 -某项

同步更新！！！！！


==============================================================
总计梯度下降算法

1：了解算法是干什么的
2：梯度下降算法的更新过程有什么意义

arfa 控制我们以多大的幅度更新参数thea_j

简单理解只有一个参数thea1

关于thea1 是一个二次曲线
不断更新

了解原理！！！！！！！！
导数向原理

了解arfa太大或太小的缺点
小步伐行走 很慢

太大  无法收敛和发散
我觉得宁愿小点也不要大了   但是小的程度自己把握 吸收下别人设置arfa值的大小

到达最低点 thea1不会在更新了 因为导数向为0 画图解决

步子会自动变小 即使不改变arfa

自动采取




