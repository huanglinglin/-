1:
如何拟合Logistic回归
的thea参数
我要定义用来拟合参数的优化目标或者代价函数

这便是监督学习问题中的Logistic回归模型的拟合问题

所以这节的目标是构造一个关于thea的代价函数　　用于去优化thea　使得最终得到的决策边界　能更好的区分数据　　进行分类

训练集
里面有m个训练样本
每个训练样本都是用n+1维特征向量来表示

x = [x0 x1 x2 ....xn]
x0 =1 y= [0,1]


cos(h(x)^i,y^i) = 1/2(h(x^i)-y^i)^2
等于1/2的平方误差

对于这个代价函数的理解是这样的

它是在输出的预测值是h(x)　而实际
标签是y的情况下　我们希望付出的代价

代价值被定义为　1/2(h(x)-y)

非凸函数

而且　h(x)是一个非线性函数

找到一个凸函数！！！！！！
为了去使用梯度下降算法
而且能保证找到全局最小值


这个函数就是我们想要的

cost(h(x),y) = {  -log(h(x)) if y=1
                  -log(1-h(x)) if y=0
                }

画图直观感受

如果y=1 而且h(x) = 1 代价等于０

可以通过图形看出
如果我们的实际值等于１　但是我们的预测值慢慢远离１的话
得到的代价是慢慢增大的

而且在预测值＝１　实际值＝１时　　代价为０

我们在来看看当y=0时　　代价值函数是什么样的

画图看


化简并且使用梯度下降算法去得到Logistic 算法

定义了单训练样本的代价函数













